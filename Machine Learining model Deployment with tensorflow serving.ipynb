{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learining model Deployment with tensorflow serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "#### 1.1 What is Tensorflow Serving ?\n",
    "\n",
    "TensorFlow Serving is a flexible, high-performance serving system for machine learning models, designed for production environments. TensorFlow Serving makes it easy to deploy new algorithms and experiments, while keeping the same server architecture and APIs. TensorFlow Serving provides out-of-the-box integration with TensorFlow models, but can be easily extended to serve other types of models and data.\n",
    "\n",
    "\n",
    "<img src=\"Images/Tensorflow_serving.png\">\n",
    "\n",
    "#### 1.2 Why use tensorflow serving ?\n",
    "\n",
    "- Highly scalable model serving solution\n",
    "- Works well for large models up to 2GB\n",
    "- Production ready Model Serving\n",
    "- Model Version Control\n",
    "- Consistent export format\n",
    "- REST and gRPC endpoints\n",
    "- Docker images are available for CPU and GPU hardware\n",
    "\n",
    "#### 1.3 When to use Tensorflow Serving ?\n",
    "\n",
    "This diagram compares various current frameworks for productionizing the machine learning models. \n",
    "\n",
    "Each framework has it's benefits and drawbacks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Load Data\n",
    "\n",
    "#### Dataset\n",
    "https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
    "\n",
    "- We will only use \"Score\" and \"Text\" columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('Dataset/Reviews.csv')\n",
    "print(df.shape)\n",
    "df[['Score','Text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.loc[:, df.columns != 'Score'], df['Score'], train_size=0.67, random_state=42)\n",
    "X_train['Rating']=y_train\n",
    "X_test['Rating']=y_test\n",
    "X_train=X_train[['Rating','Text']]\n",
    "X_test=X_test[['Rating','Text']]\n",
    "\n",
    "# Already created\n",
    "# X_train.to_csv('Dataset/train.csv')\n",
    "# X_test.to_csv('Dataset/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Preprocessing Data\n",
    "\n",
    "Let's create function which can load and preprocess train - validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path,num_samples):\n",
    "    df=pd.read_csv(file_path,nrows=num_samples)    \n",
    "    text=df['Text'].tolist()\n",
    "    text=[str(t).encode('ascii','replace') for t in text]\n",
    "    text=np.array(text,dtype=object)[:]\n",
    "    \n",
    "    labels=df['Rating'].tolist()\n",
    "    labels=[1 if i >=4 else 0 if i==3 else -1 for i in labels]\n",
    "    labels=np.array(pd.get_dummies(labels),dtype=int)[:]\n",
    "    \n",
    "    return labels,text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for testing if the function is working \n",
    "tmp_labels,tmp_text=load_dataset('Dataset/train.csv',100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Building the Classification Model using TF Hub\n",
    "\n",
    "https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\n",
    "\n",
    "- We will use google's pre-trained model which is Token based text embedding trained on English Google News 200B corpus\n",
    "- We will use **transfer learning** to change it for our use case by adding few dense layers and softmax layer for classification task\n",
    "\n",
    "To this pre-trained model we will be :- \n",
    "- Adding 64 dense layers\n",
    "- Adding softmax layer of 3 (positive sentiment, neural sentiment, negative sentiment)\n",
    "- using categorical_crossentropy as loss function\n",
    "- adam optimizer will be used\n",
    "- metrics will be accuracy\n",
    "\n",
    "**Let's write a fuction to get the get model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\", output_shape=[128], \n",
    "                           input_shape=[], dtype=tf.string, name='input', trainable=False)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(hub_layer)\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(3, activation='softmax', name='output'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='Adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only to show how pretrained model generates output\n",
    "# embed = hub.load(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\")\n",
    "# embeddings = embed([\"whats is your name\", \"let's generate embeddings\"])\n",
    "# print(embeddings.shape)\n",
    "# del embed, embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We see that for 2 input we generate two 128 embbedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (KerasLayer)           (None, 128)               124642688 \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 124,651,139\n",
      "Trainable params: 8,451\n",
      "Non-trainable params: 124,642,688\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fa26eab5f90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only for testing if the function is working \n",
    "#get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Training Process\n",
    "\n",
    "\n",
    "Let's create a fuction for training purposes:\n",
    "\n",
    "- Epochs defaulted value 5, can be change by parameter (eg for CV or for grid search)\n",
    "- Batch Size defaulted to 32\n",
    "- Train_file/ Test_file for sentiment analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(EPOCHS=5, BATCH_SIZE=32, TRAIN_FILE='Dataset/train.csv', VAL_FILE='Dataset/test.csv'):\n",
    "    WORKING_DIR = os.getcwd() #use to specify model checkpoint path\n",
    "    print(\"Loading training/validation data ...\")\n",
    "    y_train, x_train = load_dataset(TRAIN_FILE, num_samples=100000)\n",
    "    y_val, x_val = load_dataset(VAL_FILE, num_samples=10000)\n",
    "\n",
    "    print(\"Training the model ...\")\n",
    "    model = get_model()\n",
    "    model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1,\n",
    "              validation_data=(x_val, y_val),\n",
    "              callbacks=[tf.keras.callbacks.ModelCheckpoint(os.path.join(WORKING_DIR,\n",
    "                                                                         'model_checkpoint'),\n",
    "                                                            monitor='val_loss', verbose=1,\n",
    "                                                            save_best_only=True,\n",
    "                                                            save_weights_only=False,\n",
    "                                                            mode='auto')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Train and Export Model as Protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training/validation data ...\n",
      "Training the model ...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (KerasLayer)           (None, 128)               124642688 \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 124,651,139\n",
      "Trainable params: 8,451\n",
      "Non-trainable params: 124,642,688\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 0.5317 - accuracy: 0.8010\n",
      "Epoch 00001: val_loss improved from inf to 0.51023, saving model to /Users/maitreytalware/Documents/GitHub/ML-Model-Deployment-with-TensorFlow-Serving/model_checkpoint\n",
      "WARNING:tensorflow:From /Users/maitreytalware/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/maitreytalware/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/maitreytalware/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/maitreytalware/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/maitreytalware/Documents/GitHub/ML-Model-Deployment-with-TensorFlow-Serving/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/maitreytalware/Documents/GitHub/ML-Model-Deployment-with-TensorFlow-Serving/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 1468s 470ms/step - loss: 0.5317 - accuracy: 0.8010 - val_loss: 0.5102 - val_accuracy: 0.8075\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 0.5052 - accuracy: 0.8077\n",
      "Epoch 00002: val_loss improved from 0.51023 to 0.49768, saving model to /Users/maitreytalware/Documents/GitHub/ML-Model-Deployment-with-TensorFlow-Serving/model_checkpoint\n",
      "INFO:tensorflow:Assets written to: /Users/maitreytalware/Documents/GitHub/ML-Model-Deployment-with-TensorFlow-Serving/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/maitreytalware/Documents/GitHub/ML-Model-Deployment-with-TensorFlow-Serving/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 1362s 436ms/step - loss: 0.5052 - accuracy: 0.8077 - val_loss: 0.4977 - val_accuracy: 0.8155\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 0.4968 - accuracy: 0.8111\n",
      "Epoch 00003: val_loss improved from 0.49768 to 0.48834, saving model to /Users/maitreytalware/Documents/GitHub/ML-Model-Deployment-with-TensorFlow-Serving/model_checkpoint\n",
      "INFO:tensorflow:Assets written to: /Users/maitreytalware/Documents/GitHub/ML-Model-Deployment-with-TensorFlow-Serving/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/maitreytalware/Documents/GitHub/ML-Model-Deployment-with-TensorFlow-Serving/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 1292s 413ms/step - loss: 0.4968 - accuracy: 0.8111 - val_loss: 0.4883 - val_accuracy: 0.8162\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 0.4901 - accuracy: 0.8134\n",
      "Epoch 00004: val_loss did not improve from 0.48834\n",
      "3125/3125 [==============================] - 1272s 407ms/step - loss: 0.4901 - accuracy: 0.8134 - val_loss: 0.4903 - val_accuracy: 0.8147\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 0.4840 - accuracy: 0.8152\n",
      "Epoch 00005: val_loss improved from 0.48834 to 0.48816, saving model to /Users/maitreytalware/Documents/GitHub/ML-Model-Deployment-with-TensorFlow-Serving/model_checkpoint\n",
      "INFO:tensorflow:Assets written to: /Users/maitreytalware/Documents/GitHub/ML-Model-Deployment-with-TensorFlow-Serving/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/maitreytalware/Documents/GitHub/ML-Model-Deployment-with-TensorFlow-Serving/model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 1285s 411ms/step - loss: 0.4840 - accuracy: 0.8152 - val_loss: 0.4882 - val_accuracy: 0.8159\n",
      "INFO:tensorflow:Assets written to: Sentiment_Model/1601531800/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Sentiment_Model/1601531800/assets\n"
     ]
    }
   ],
   "source": [
    "def export_model(model, base_path=\"Sentiment_Model/\"):\n",
    "    path = os.path.join(base_path, str(int(time.time())))\n",
    "    tf.saved_model.save(model, path)\n",
    "\n",
    "if __name__== '__main__':\n",
    "    model = train()\n",
    "    export_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Testing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72817457, 0.01399327, 0.2578322 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = \"horrible book, waste of time\"\n",
    "model.predict([test_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00663852, 0.00293764, 0.99042386]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = \"Awesome book.\"\n",
    "model.predict([test_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Tensorflow Serving with Docker\n",
    "\n",
    "`docker run -p 8500:8500 \\\n",
    "            -p 8501:8501 \\\n",
    "            --mount type=bind,\\\n",
    "            source=/path/Sentiment_Model/,\\\n",
    "            target=/models/Sentiment_Model \\\n",
    "            -e MODEL_NAME=Sentiment_Model \\\n",
    "            -t tensorflow/serving`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support for gRPC and REST\n",
    "\n",
    "- TensorFlow Serving supports\n",
    "    - Remote Procedure Protocal (gRPC)\n",
    "    - Representational State Transfer (REST)\n",
    "- Consistent API structures\n",
    "- Server supports both standards simultaneously\n",
    "- Default ports:\n",
    "    - RPC: 8500\n",
    "    - REST: 8501"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9: Setup a REST Client to Perform Model Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions via REST\n",
    "\n",
    "- Standard HTTP POST requests\n",
    "- Response is a JSON body with the prediction\n",
    "- Request from the default or specific model\n",
    "\n",
    "Default URI scheme:\n",
    "\n",
    "`http://{HOST}:{PORT}/v1/models/{MODEL_NAME}`\n",
    "\n",
    "Specific model versions:\n",
    "\n",
    "`http://{HOST}:{PORT}/v1/models/{MODEL_NAME}[/versions/{MODEL_VERSION}]:predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing tf_serving_rest_client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tf_serving_rest_client.py\n",
    "import json\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "def get_rest_url(model_name, host='127.0.0.1', port='8501', verb='predict', version=None):\n",
    "    \"\"\" generate the URL path\"\"\"\n",
    "    url = \"http://{host}:{port}/v1/models/{model_name}\".format(host=host, port=port, model_name=model_name)\n",
    "    if version:\n",
    "        url += 'versions/{version}'.format(version=version)\n",
    "    url += ':{verb}'.format(verb=verb)\n",
    "    return url\n",
    "\n",
    "\n",
    "def get_model_prediction(model_input, model_name='Sentiment_Model', signature_name='serving_default'):\n",
    "    \"\"\" no error handling at all, just poc\"\"\"\n",
    "\n",
    "    url = get_rest_url(model_name)\n",
    "    #In the row format, inputs are keyed to instances key in the JSON request.\n",
    "    #When there is only one named input, specify the value of instances key to be the value of the input:\n",
    "    data = {\"instances\": [model_input]}\n",
    "    \n",
    "    rv = requests.post(url, data=json.dumps(data))\n",
    "    if rv.status_code != requests.codes.ok:\n",
    "        rv.raise_for_status()\n",
    "    \n",
    "    return rv.json()['predictions']\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    print(\"\\nGenerate REST url ...\")\n",
    "    url = get_rest_url(model_name='Sentiment_Model')\n",
    "    print(url)\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\nEnter an Sentiment review [:q for Quit]\")\n",
    "        if sys.version_info[0] <= 3:\n",
    "            sentence = input()\n",
    "        if sentence == ':q':\n",
    "            break\n",
    "        model_input = sentence\n",
    "        model_prediction = get_model_prediction(model_input)\n",
    "        print(\"The model predicted ...\")\n",
    "        print(model_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10: Setup a gRPC Client to Perform Model Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified from [https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/mnist_client.py](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/mnist_client.py#L152)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions via gRPC\n",
    "\n",
    "More sophisticated client-server connections\n",
    "\n",
    "- Prediction data has to be converted to the Protobuf format\n",
    "- Request types have designated types, e.g. float, int, bytes\n",
    "- Payloads need to be converted to base64\n",
    "- Connect to the server via gRPC stubs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gRPC vs REST: When to use which API standard\n",
    "\n",
    "- Rest is easy to implement and debug\n",
    "- RPC is more network efficient, smaller payloads\n",
    "- RPC can provide much faster inferences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import grpc\n",
    "from grpc.beta import implementations\n",
    "import tensorflow as tf\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2, get_model_metadata_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('base')",
   "language": "python",
   "name": "python37764bitbase1e1bdca11d8e4711ab07c0d817e889d5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
